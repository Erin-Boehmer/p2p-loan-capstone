{
 "metadata": {
  "name": "",
  "signature": "sha256:983aef0e8ae009fd3eff2cc86c2007ec3ed2ae12097f3a9de5b0d5fca931d97c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import bz2\n",
      "import random\n",
      "\n",
      "from lifelines.utils import concordance_index\n",
      "\n",
      "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
      "from sklearn.linear_model import BayesianRidge, ElasticNet\n",
      "from sklearn.neural_network import BernoulliRBM\n",
      "from sklearn.grid_search import GridSearchCV"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "loans = pd.read_csv('data/LoanStats3.csv.bz2', compression='bz2', low_memory=False, index_col=0)\n",
      "outcomes = pd.read_csv('data/outcomes.csv', low_memory=False)\n",
      "outcomes.rename(columns={'loan_id': 'id'}, inplace=True)\n",
      "outcomes.set_index('id', inplace=True)\n",
      "del outcomes['Unnamed: 0']\n",
      "df = loans.join(outcomes, how='inner')\n",
      "\n",
      "# Clean the term column\n",
      "df['term'] = df['term'].map(lambda x: int(x.strip(' months')))\n",
      "\n",
      "# Clean the grade column\n",
      "df['grade'] = df['grade'].map(lambda x: ord(x) - ord('A'))\n",
      "df['sub_grade'] = df['sub_grade'].map(lambda x: (ord(x[0])-ord('A')) * 5 + int(x[1]))\n",
      "\n",
      "print \"Created dataset\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Created dataset\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_columns = ['loan_amnt', 'term', 'grade', 'sub_grade', 'annual_inc',\n",
      "                   'fico_range_low', 'fico_range_high', 'last_fico_range_low',\n",
      "                   'last_fico_range_high', 'riskFreeRate']\n",
      "\n",
      "clean_df = df.dropna(subset=feature_columns+['npv', 'npvPseudo'])\n",
      "print len(clean_df.index)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "525007\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features = clean_df[feature_columns]\n",
      "labels = clean_df[['npvPseudo']]\n",
      "scoring_labels = clean_df[['npv']]\n",
      "\n",
      "test_samples = int(0.1 * len(clean_df.index))\n",
      "test_rows = random.sample(clean_df.index.values, test_samples)\n",
      "print len(test_rows)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "52500\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_features = features.ix[test_rows].as_matrix()\n",
      "test_labels = labels.ix[test_rows].as_matrix()\n",
      "test_score_labels = scoring_labels.ix[test_rows].as_matrix()\n",
      "test_is_complete = clean_df[['finalStatusIsComplete']].ix[test_rows].as_matrix()\n",
      "\n",
      "train_features = features.drop(test_rows).as_matrix()\n",
      "train_labels = labels.drop(test_rows).as_matrix()\n",
      "train_score_labels = scoring_labels.drop(test_rows).as_matrix()\n",
      "print \"Created train and test data\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Created train and test data\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rf = RandomForestRegressor(n_estimators=50, min_samples_leaf=5)\n",
      "\n",
      "rf.fit(train_features, train_labels.ravel())\n",
      "predicted_npv = rf.predict(test_features)\n",
      "print \"Normal Score:\", rf.score(test_features, test_labels.ravel())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Normal Score: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.453913229141\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print test_score_labels.ravel().shape, predicted_npv.shape, test_is_complete.ravel().shape\n",
      "concordance_score = 1 - concordance_index(test_score_labels.ravel(), -predicted_npv, test_is_complete.ravel())\n",
      "print \"Concordance Score:\", concordance_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(52500,) (52500,) (52500,)\n",
        "Concordance Score:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.807732763499\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def testModel(model):\n",
      "    model.fit(train_features, train_labels.ravel())\n",
      "    predicted_npv = model.predict(test_features)\n",
      "    print \"Normal Score:\", model.score(test_features, test_labels.ravel())\n",
      "    \n",
      "    concordance_score = 1 - concordance_index(test_score_labels.ravel(), -predicted_npv, test_is_complete.ravel())\n",
      "    print \"Concordance Score:\", concordance_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Ridge regression\"\n",
      "testModel(BayesianRidge())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Ridge regression\n",
        "Normal Score:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.255758203446\n",
        "Concordance Score:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.734484968531\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Gradient Boosting\"\n",
      "testModel(GradientBoostingRegressor())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Gradient Boosting\n",
        "Normal Score:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.432382075158\n",
        "Concordance Score:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.80477115143\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Ada Boosting\"\n",
      "testModel(AdaBoostRegressor())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Ada Boosting\n",
        "Normal Score:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.229389752735\n",
        "Concordance Score:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.739947766725\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"ElasticNet\"\n",
      "testModel(ElasticNet())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ElasticNet\n",
        "Normal Score:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.253382363492\n",
        "Concordance Score:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.729135859845\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RBM\n"
       ]
      },
      {
       "ename": "AttributeError",
       "evalue": "'BernoulliRBM' object has no attribute 'predict'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-15-28b7e83db66c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"RBM\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtestModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBernoulliRBM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-8-9f0c664b2d40>\u001b[0m in \u001b[0;36mtestModel\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtestModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpredicted_npv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Normal Score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mAttributeError\u001b[0m: 'BernoulliRBM' object has no attribute 'predict'"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}